201028_YOLOv5セットアップ.txt
-------------------------------------------------------------------------
# ---------------------------------------------
# 事前にPython3.8とtorch>=1.6以上をインストール
# ---------------------------------------------
# 詳しくは、以下を参照。anaconda3インストール時、jupyter-notebookもインストールされる
# 200912_ubuntu1804_Anaconda(jupyternotebook)_cuDNN_pytorchl.txt


# --------------------------
# Anaconda3の環境をaliasから呼び出す
# --------------------------
# .bashrc内に以下を記述
# alias conda_start='export PATH=~/anaconda3/bin:$PATH'

# ターミナルを開きalias呼び出し(condaスタート)
conda_start


# --------------------------------
# YOLO v5ソースコード入手&環境構築
# --------------------------------
# 参考: https://lionbridge.ai/ja/articles/yolov5-object-detection/
# ソース入手
git clone https://github.com/ultralytics/yolov5

# 環境構築(事前にaliasでanaconda3の環境に移行)
cd yolov5
pip install -U -r requirements.txt


# -----------------------------------------------------
# Trainingフォルダを作成し、datasetフォルダを内部に生成
# -----------------------------------------------------
!mkdir training
cd training
!mkdir dataset

# --------------------------------
# ARCdatasetからrgb_jpgを作成し、datasetを作成
# --------------------------------
# http://mprg.jp/research/arc_dataset_2017_j
# 上記から「ARCdataset_png.zip」を入手。
# 解凍後、①内のpng画像を、②内にjpg変換し格納
# windowsのirfanviewを使うと、フォルダ単位で画像形式変換可能
# irfanview : https://forest.watch.impress.co.jp/library/software/irfanview/
# 
# ① ARCdataset_png/train/rgb      #  元画像(png)
# ② ARCdataset_png/train/rgb_jpg  #変換画像(jpg)
# 
# ③ ARCdataset_png/train/boundingbox
# アノテーションフォルダ③と②の中身をdatasetフォルダ内に入れる
# yolov5/training/dataset
#  ├2017-002-1.jpg
#  ├2017-002-1.txt
#  ├2017-002-2.jpg
#  ├2017-002-2.txt
#  ・

# --------------------------------
# ARCdatasetからtrainとvalidを生成
# --------------------------------
# yolov5のフォルダ上で、以下のコマンドを入力し、jupyter-notebook起動
cd yolov5/training
jupyter-notebook

# https://lionbridge.ai/ja/articles/yolov5-object-detection/
# 独自のデータセットフォルダをこのフォルダにコピーし、シンプルなtrain_val_folder_split.ipynb
# の下のコースを、train_val_folder_split.ipynbとして実行(.pyとして出力してもOK）
# 参考: Screenshot_train_val_folder_split.jpg


# -------------------------------------------------
# trainingフォルダにdataset.yamlとmodel.yamlをセット
# -------------------------------------------------
# yolov5/trainingに以下の二つを追加
#
# dataset.yaml
# -------------------------------------------
# # train and val datasets (image directory or *.txt file with image paths)
# train: training/data/images/train/
# val: training/data/images/valid/
# 
# # number of classes
# nc: 41
# 
# # class names
# names: ['BG', 'Item1', 'Item2',・・,'Item40']
# -------------------------------------------

# model.yaml
# yolov5/models/yolov5l.yamlのファイルをトレーニングフォルダにコピーし
# nc(クラス数)を41に変更
# -------------------------------------------
# # parameters
# nc: 41 # change number of classes
# depth_multiple: 1.0 # model depth multiple
# width_multiple: 1.0 # layer channel multiple
# 　・
# 　・
# -------------------------------------------


# -------------------------------------------------
# training開始
# -------------------------------------------------
cd yolov5

# Train yolov5l on custom dataset for 300 epochs
python train.py --img 1280 --batch 16 --epochs 300 --data training/dataset.yaml --cfg training/yolov5l.yaml --weights '' --device 0

# 以下のエラーが出る場合、--batch 1 などでバッチサイズを小さくする 
# RuntimeError: CUDA out of memory. Tried to allocate 200.00 MiB (GPU 0; 7.93 GiB total capacity; 6.85 GiB already allocated; 57.75 MiB free; 6.94 GiB reserved in total by PyTorch)
# 参考: https://github.com/ultralytics/yolov5/issues/1040
python train.py --img 1280 --batch 1 --epochs 300 --data training/dataset.yaml --cfg training/yolov5l.yaml --weights '' --device 0

# まだエラーが出る場合、モデルを軽くする (Geforce 1080など。batch1、yolov5m.yaml)
python train.py --img 1280 --batch 1 --epochs 300 --data training/dataset.yaml --cfg training/yolov5m.yaml --weights '' --device 0

# -------------------------------------------------
# 途中結果の確認(tensorboard活用)
# -------------------------------------------------
# 別ターミナルを起動し、yolov5のフォルダ上でalias呼び出し(condaスタート)
conda_start

# tensorboard起動
# 終了はCTRL+C
# 下記コマンド後、URLで確認可能→　http://localhost:6006/
tensorboard --logdir=runs

# -------------------------------------------------
# 途中結果の確認(runs/expX/results.txt)
# -------------------------------------------------
     EPOCH     gpu_mem     box       obj       cls     total   targets  img_size         P         R     mAP@.5  mAP@.5-.95 val_loss(box, obj, cls)
                                                                                 precision    recall    mAP_0.5  mAP_0.5:0/95  box    object    class
                                                                                    適合率    再現率   複数class平均適合率    loss     loss     loss
-----------------------------------------------------------------------------------------------------------------------------------------------------
     0/299     3.81G   0.06137   0.02314   0.05899    0.1435         7      1280         0         0 0.0009165 0.0001907   0.04028    0.0164    0.0456
     1/299     7.38G   0.05249   0.02003   0.05658    0.1291         9      1280         0         0  0.001736 0.0004825   0.03712   0.01393   0.04256
      ・
   200/299     7.38G   0.01642   0.01123   0.01327   0.04092         1      1280     0.621    0.7872     0.765     0.497   0.01296  0.009445  0.009567
